# Introduction  

In order to study the **partially observable Markov decision process** (**POMDP**), we have worked with [LunarLander-v2](https://gym.openai.com/envs/LunarLander-v2/) OpenAI Gym environment. Four different methods were implemented : 

 	1. SARSA
 	2. Q-Learning
 	3. DQN
 	4. DQN bonus

 We have tested their performance in two different situations, blind area width = 0.2 / 0.4.

# Install

You may encounter some problem with the environment LunarLander-v2. This link could be helpful.

https://stackoverflow.com/questions/64161280/rl-problem-on-colab-for-gym-envs-box2d-has-no-attribute-lunarlander

 

# Usage

To run our program, you will only need to open ''Lunarlander_with_blind_area.ipynb". 
